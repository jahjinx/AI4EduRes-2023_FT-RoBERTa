{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:300%;\">AI4EduRes'2023: <br />Fine-Tuning RoBERTa for Downstream Tasks</h1>\n",
    "<p>This notebook details how to use RoBERTa with HuggingFace.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìΩÔ∏è IMDb Review Sentiment Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Platform Check\n",
    "Ensure we're on an ARM environment. \n",
    "\n",
    "NOTE:  If you are not on an ARM environment, update `params.device` to `torch.device('cuda' if torch.cuda.is_available() else 'cpu')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're Armed: macOS-13.0-arm64-i386-64bit\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "\n",
    "if platform.platform() == 'macOS-13.0-arm64-i386-64bit':\n",
    "    print(f\"We're Armed: {platform.platform()}\")\n",
    "else:\n",
    "    print(f\"WARNING! NOT ARMED: {platform.platform()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import params\n",
    "\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from datasets import load_from_disk\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "from transformers import RobertaForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "# suppress model warning\n",
    "from transformers import logging\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust parameters if necessary\n",
    "params.num_labels = 2\n",
    "params.output_dir = \"models/imdb_hf\"\n",
    "params.max_length = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMDb\n",
    "\n",
    "For this notebook, I've prepared a train/validate/test split of the IMDb movie review dataset. I've also mapped the string sentiment labels to binary integers and renamed the columns to \"text\" and \"label\". I've saved that dataset as a HuggingFace dataset object for the purposes of demonstrating the HuggingFace framework. Here, I load the dataset from a local directory. \n",
    "\n",
    "HuggingFace also offers a large selection of datasets that can be loaded from their remote repository using `from datasets import load_dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jarradjinx/opt/anaconda3/envs/workshop_present_env/lib/python3.9/site-packages/datasets/dataset_dict.py:1241: FutureWarning: 'fs' was is deprecated in favor of 'storage_options' in version 2.8.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'storage_options=fs.storage_options' instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "imdb = load_from_disk(\"data/inter_IMDB_sentiment/IMDb.hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 36000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 4000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Beautifully photographed and ably acted, generally, but the writing is very slipshod. There are scenes of such unbelievability that there is no joy in the watching. The fact that the young lover has a twin brother, for instance, is so contrived that I groaned out loud. And the \"emotion-light bulb connection\" seems gimmicky, too.<br /><br />I don\\'t know, though. If you have a few glasses of wine and feel like relaxing with something pretty to look at with a few flaccid comedic scenes, this is a pretty good movie. No major effort on the part of the viewer required. But Italian film, especially Italian comedy, is usually much, much better than this.',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View Example\n",
    "imdb[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess\n",
    "Below, we prepare our input text sequences to be accepted by the model. This involves tokenization and encoding of our sequences.\n",
    "\n",
    "<b>Tokenization</b> :  Splitting strings into word or sub-word token strings <br />\n",
    "<b>Encoding</b> : Converting those token strings into integers<br />\n",
    "\n",
    "The preprocessing function will tokenize and encode our strings according to RoBERTa's pre-defined tokenization and encoding dictionary. When used in conjunction with HuggingFace Datasets and the mapping function, the result is the addition of token/input_ids and attention mask columns to our Dataset:\n",
    "\n",
    "<b>token/input ids</b> : A list of integers that represent our tokenized and encoded string<br />\n",
    "<b>attention masks</b> : A list of 1's and 0's mapped to each token id. 1 represents an id to which the model should apply attention and 0 represents an id to which the model may not apply attention (padding tokens, for example).\n",
    "\n",
    "It is important to note that our preprocessing function's tokenizer is set only to truncate sequences longer than `max_length` to `max_length`. Sequences shorter than `max_length` will need to be padded,  which is possible via the tokenizer. However, padding at this point will pad all sequences to `max_length` which is unnecessary and computationally inefficient as explained below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return params.tokenizer(examples[\"text\"], \n",
    "                            max_length = params.max_length, # 256 in this example\n",
    "                            truncation=True) # truncate sequences longer than max_length to max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/jarradjinx/Library/Mobile Documents/com~apple~CloudDocs/EDU_leeds/LD_research/AI4EduRes'2023_FT-RoBERTa/data/inter_IMDB_sentiment/IMDb.hf/train/cache-8aaa70961af00f55.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "343b1f4384894631851d48d0d90696f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eb923fec7784bc190cc9a759205b665",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_imdb = imdb.map(preprocess_function, batched=True)\n",
    "\n",
    "# removing unneeded columns avoids warning in training loop\n",
    "tokenized_imdb = tokenized_imdb.remove_columns(\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 36000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 4000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_imdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Data Collator\n",
    "\n",
    "By creating a collator that collects and combines portions of our dataset, we are able to refine the way data is handed to the model. Specifically, the DataCollatorWithPadding will collect our data into batches of a pre-defined size (`params.batch_size`). It will then pad all sequences within that batch to the length of the longest sequence within given batch. Finally, it converts the batch to a tensor before handing it to the model. This process is called dynamic padding.\n",
    "\n",
    "Dynamic padding increases the efficiency of forwarding data through the model as sequences may be shorter than `max_length`. If we pad our sequences and convert them to tensors without collation, every sequence given to the model will be `max_length`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=params.tokenizer,\n",
    "                                        padding='max_length',\n",
    "                                        max_length=params.max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Training Metrics\n",
    "\n",
    "If you would like to view metrics other than loss during training, specifically in relation to the validation loop, you may load those metrics in a computational function as shown below. This function must pass predictions and labels to [compute](https://huggingface.co/docs/evaluate/main/en/package_reference/main_classes#evaluate.EvaluationModule.compute) to calculate your defined metrics. \n",
    "\n",
    "This function will be given to the Trainer below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    metric1 = evaluate.load(\"accuracy\")\n",
    "    metric2 = evaluate.load(\"f1\")\n",
    "    \n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    accuracy = metric1.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
    "    f1 = metric2.compute(predictions=predictions, references=labels)[\"f1\"]\n",
    "    return {\"accuracy\": accuracy, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & View Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==============================================================================================================\n",
       "Layer (type:depth-idx)                                       Output Shape              Param #\n",
       "==============================================================================================================\n",
       "RobertaForSequenceClassification                             [1, 2]                    --\n",
       "‚îú‚îÄRobertaModel: 1-1                                          [1, 512, 768]             --\n",
       "‚îÇ    ‚îî‚îÄRobertaEmbeddings: 2-1                                [1, 512, 768]             --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄEmbedding: 3-1                                   [1, 512, 768]             38,603,520\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄEmbedding: 3-2                                   [1, 512, 768]             768\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄEmbedding: 3-3                                   [1, 512, 768]             394,752\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 3-4                                   [1, 512, 768]             1,536\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 3-5                                     [1, 512, 768]             --\n",
       "‚îÇ    ‚îî‚îÄRobertaEncoder: 2-2                                   [1, 512, 768]             --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-6                                  --                        85,054,464\n",
       "‚îú‚îÄRobertaClassificationHead: 1-2                             [1, 2]                    --\n",
       "‚îÇ    ‚îî‚îÄDropout: 2-3                                          [1, 768]                  --\n",
       "‚îÇ    ‚îî‚îÄLinear: 2-4                                           [1, 768]                  590,592\n",
       "‚îÇ    ‚îî‚îÄDropout: 2-5                                          [1, 768]                  --\n",
       "‚îÇ    ‚îî‚îÄLinear: 2-6                                           [1, 2]                    1,538\n",
       "==============================================================================================================\n",
       "Total params: 124,647,170\n",
       "Trainable params: 124,647,170\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 124.65\n",
       "==============================================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 427.83\n",
       "Params size (MB): 498.59\n",
       "Estimated Total Size (MB): 926.42\n",
       "=============================================================================================================="
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the RobertaForSequenceClassification model\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base',\n",
    "                                                         num_labels = params.num_labels,\n",
    "                                                         output_attentions = False,\n",
    "                                                         output_hidden_states = False,\n",
    "                                                         )\n",
    "\n",
    "# view the model summary by passing dummy data of compatible shape\n",
    "from torchinfo import summary\n",
    "summary(model, input_size=(1, 512), dtypes=['torch.IntTensor'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "\n",
    "Before training, we define all of our training hyperparameters via [TrainingArguments](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments). The only required parameter is `output_dir` while all other arguments have default values set. Here, we define many of our own parameters.\n",
    "\n",
    "We then instantiate the [Trainer](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer) with our model, training arguments, dataset splits, tokenizer, collator and metrics function.\n",
    "\n",
    "Finally, we start fine-tuning our model by calling [train()](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer.train)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    disable_tqdm=False, # show training progress\n",
    "    output_dir=params.output_dir, # \"imdb_hf\"\n",
    "    learning_rate=params.learning_rate,\n",
    "    optim=\"adamw_torch\",\n",
    "    per_device_train_batch_size=params.batch_size,\n",
    "    per_device_eval_batch_size=params.batch_size,\n",
    "    num_train_epochs=params.epochs,\n",
    "    evaluation_strategy=\"epoch\", # eval at each epoch\n",
    "    logging_strategy=\"epoch\", # show info each epoch  \n",
    "    save_strategy=\"epoch\", # save at each epoch\n",
    "    load_best_model_at_end=True, #\n",
    "    use_mps_device=True, # use MPS, remove if using GPU\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_imdb[\"train\"],\n",
    "    eval_dataset=tokenized_imdb[\"validation\"],\n",
    "    tokenizer=params.tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model to our training data - fine-tuning\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: left;\"><img src=\"presentation_resources/hf_training.png\"  align=\"left\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "Once a model is fine-tuned, we can load the model, its tokenizer, pre-process new input and generate predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports for Inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import RobertaTokenizer\n",
    "from transformers import TextClassificationPipeline\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infer Manually w/HuggingFace\n",
    "First, load our selected fine-tuned model and its tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file models/imdb_hf/checkpoint-4500/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"models/imdb_hf/checkpoint-4500\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file models/imdb_hf/checkpoint-4500/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at models/imdb_hf/checkpoint-4500.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n",
      "loading file vocab.json\n",
      "loading file merges.txt\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "PATH = 'models/imdb_hf/checkpoint-4500'\n",
    "model = AutoModelForSequenceClassification.from_pretrained(PATH, local_files_only=True)\n",
    "tokenizer = RobertaTokenizer.from_pretrained(PATH, local_files_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we tokenize our test input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[   0,  100, 4157,   42, 1569,  328,    2],\n",
      "        [   0,  100,  657,   42, 1569,  328,    2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "# input = tokenizer(\"I hate this movie!\", return_tensors=\"pt\")\n",
    "inputs = tokenizer([\"I hate this movie!\", \"I love this movie!\"], return_tensors=\"pt\")\n",
    "\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forward those inputs through the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.3273, -3.2752],\n",
       "        [-3.2370,  3.5497]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "\n",
    "logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classes are mapped by index. Because our classification head uses a softmax function on the output layer, the index with the highest value corresponds to our predicted label. In this case, 0 = \"Negative (Sentiment)\" and 1 = \"Positive (Sentiment)\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>I hate this movie!</s> 0\n",
      "<s>I love this movie!</s> 1\n"
     ]
    }
   ],
   "source": [
    "# loop through logits\n",
    "for i, v in enumerate(logits):\n",
    "    # get index of largest value\n",
    "    predicted_class_id = v.argmax().item()\n",
    "    # get & decode input, match with predicted_class_id\n",
    "    print(params.tokenizer.decode((inputs['input_ids'][i])), predicted_class_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infer with HugginFace Pipeline\n",
    "\n",
    "HuggingFace's pipeline method allows us to streamline the inference process further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file models/imdb_hf/checkpoint-4500/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"models/imdb_hf/checkpoint-4500\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file models/imdb_hf/checkpoint-4500/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at models/imdb_hf/checkpoint-4500.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n",
      "loading file vocab.json\n",
      "loading file merges.txt\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "PATH = 'models/imdb_hf/checkpoint-4500'\n",
    "model = AutoModelForSequenceClassification.from_pretrained(PATH, local_files_only=True)\n",
    "tokenizer = RobertaTokenizer.from_pretrained(PATH, local_files_only=True)\n",
    "\n",
    "# define pipeline\n",
    "pipe = TextClassificationPipeline(model=model, tokenizer=tokenizer, top_k=2, max_length=512, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'LABEL_0', 'score': 0.9987990856170654},\n",
       "  {'label': 'LABEL_1', 'score': 0.001200946164317429}]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(\"i hate this movie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Whole Test Set & Evaluate\n",
    "We will use the HuggingFace pipeline with a loop in order to generate predictions for our entire test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Test Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Test Data\n",
    "imdb = load_from_disk(\"data/inter_IMDB_sentiment/IMDb.hf\")\n",
    "\n",
    "imdb_test = imdb['test']\n",
    "\n",
    "imdb_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sequences\n",
    "test_input = imdb_test['text']\n",
    "\n",
    "test_output = []\n",
    "\n",
    "# pipe sequences to tokenizer -> model\n",
    "with tqdm(test_input, unit=\"test\") as prog:\n",
    "    for step, test in enumerate(prog):\n",
    "        prog.set_description(f\"Test {step+1}\")\n",
    "        # append results to test_output list\n",
    "        test_output.append(pipe(test)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test Output Slice:\")\n",
    "test_output[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse target predictions to new list\n",
    "predictions = []\n",
    "\n",
    "for i in test_output:\n",
    "    predictions.append(i[0]['label'])\n",
    "    \n",
    "print(len(predictions))\n",
    "print(predictions[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove \"LABEL_\" and cast as int\n",
    "for i, v in enumerate(predictions):\n",
    "    predictions[i] = int(v.replace(\"LABEL_\",\"\"))\n",
    "\n",
    "print(predictions[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get accuracy and F1\n",
    "acc = accuracy_score(imdb_test['label'], predictions)\n",
    "f1 = f1_score(imdb_test['label'], predictions)\n",
    "\n",
    "print(\"Accuracy: \", acc)\n",
    "print(\"F1: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('workshop_present_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "67962405cad10eeeccd3e4011c192b84211e6b516afcf058c81650d23e67a1ed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
